{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d3e3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processamento em: ..\\results\\imputation\\imputed_sample_data\n",
      "Lendo 10 arquivos de ..\\results\\imputation\\imputed_sample_data\\5...\n",
      "Lendo 10 arquivos de ..\\results\\imputation\\imputed_sample_data\\10...\n",
      "Lendo 10 arquivos de ..\\results\\imputation\\imputed_sample_data\\15...\n",
      "Lendo 10 arquivos de ..\\results\\imputation\\imputed_sample_data\\20...\n",
      "\n",
      "--- Pré-visualização da Tabela ---\n",
      "\\hline \\hline\n",
      "\\multirow{2}{*}{\\textbf{Imputation Technique}} & \\multicolumn{2}{\\c}{\\textbf{5\\%}} & \\multicolumn{2}{\\c}{\\textbf{10\\%}} & \\multicolumn{2}{\\c}{\\textbf{15\\%}} & \\multicolumn{2}{\\c}{\\textbf{20\\%}} \\\\\n",
      "\\cline{2-9}\n",
      " & \\textbf{RMSE} & \\textbf{MAE} & \\textbf{RMSE} & \\textbf{MAE} & \\textbf{RMSE} & \\textbf{MAE} & \\textbf{RMSE} & \\textbf{MAE} \\\\\n",
      "\\hline\n",
      "ARIMA    & 6.26 $\\pm$ 4.52 & 1.02 $\\pm$ 0.77 & 17.84 $\\pm$ 11.96 & 4.26 $\\pm$ 3.02 & 22.36 $\\pm$ 11.54 & 6.55 $\\pm$ 3.35 & 25.74 $\\pm$ 12.63 & 9.15 $\\pm$ 4.70 \\\\\n",
      "HoltWinters & 5.47 $\\pm$ 4.86 & 0.93 $\\pm$ 0.84 & 16.62 $\\pm$ 10.43 & 3.86 $\\pm$ 2.47 & 19.71 $\\pm$ 10.64 & 5.68 $\\pm$ 2.98 & 23.83 $\\pm$ 12.47 & 8.23 $\\pm$ 4.32 \\\\\n",
      "KNN-Sklearn & 7.59 $\\pm$ 5.06 & 1.20 $\\pm$ 0.76 & 14.29 $\\pm$ 8.02 & 3.42 $\\pm$ 2.01 & 17.74 $\\pm$ 7.90 & 5.23 $\\pm$ 2.20 & 21.35 $\\pm$ 9.81 & 7.34 $\\pm$ 3.37 \\\\\n",
      "Kalman   & 8.17 $\\pm$ 4.77 & 1.28 $\\pm$ 0.81 & 163.00 $\\pm$ 159.55 & 30.17 $\\pm$ 37.56 & 173.79 $\\pm$ 164.95 & 38.17 $\\pm$ 41.62 & 169.94 $\\pm$ 136.57 & 38.87 $\\pm$ 30.61 \\\\\n",
      "LOCF     & 9.36 $\\pm$ 11.83 & 1.45 $\\pm$ 1.77 & 19.61 $\\pm$ 14.73 & 4.57 $\\pm$ 3.55 & 26.64 $\\pm$ 13.96 & 7.50 $\\pm$ 3.96 & 30.07 $\\pm$ 16.01 & 10.20 $\\pm$ 5.74 \\\\\n",
      "Linear   & 7.98 $\\pm$ 5.35 & 1.28 $\\pm$ 0.88 & 16.83 $\\pm$ 10.60 & 3.96 $\\pm$ 2.56 & 21.45 $\\pm$ 10.22 & 6.23 $\\pm$ 2.78 & 23.84 $\\pm$ 11.08 & 8.11 $\\pm$ 3.69 \\\\\n",
      "Mean     & 7.59 $\\pm$ 5.06 & 1.20 $\\pm$ 0.76 & 14.29 $\\pm$ 8.02 & 3.42 $\\pm$ 2.01 & 17.74 $\\pm$ 7.90 & 5.23 $\\pm$ 2.20 & 21.35 $\\pm$ 9.81 & 7.34 $\\pm$ 3.37 \\\\\n",
      "SVD-KNN  & 7.16 $\\pm$ 5.64 & 1.15 $\\pm$ 0.84 & 15.43 $\\pm$ 8.17 & 3.62 $\\pm$ 2.04 & 18.03 $\\pm$ 7.93 & 5.15 $\\pm$ 2.18 & 23.59 $\\pm$ 13.55 & 8.12 $\\pm$ 4.76 \\\\\n",
      "SVD-KNN-Hankel & 6.73 $\\pm$ 4.62 & 1.08 $\\pm$ 0.74 & 13.44 $\\pm$ 8.29 & 3.23 $\\pm$ 2.00 & 16.55 $\\pm$ 8.47 & 4.91 $\\pm$ 2.29 & 20.12 $\\pm$ 10.20 & 6.79 $\\pm$ 3.20 \\\\\n",
      "Spline   & 10.51 $\\pm$ 9.08 & 1.64 $\\pm$ 1.42 & 21.74 $\\pm$ 13.95 & 5.14 $\\pm$ 3.26 & 31.91 $\\pm$ 17.17 & 8.77 $\\pm$ 4.60 & 36.87 $\\pm$ 20.42 & 12.15 $\\pm$ 6.72 \\\\\n",
      "\\hline\n",
      "\n",
      "Sucesso! Tabela salva em: tabela_latex_resultados.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- Configurações ---\n",
    "# O diretório base onde as pastas 5, 10, 15, 20 estão\n",
    "BASE_PATH =  os.path.join('..','results','imputation','imputed_sample_data')\n",
    "# As pastas de taxas de missing data que você quer processar\n",
    "MISSING_RATES = ['5', '10', '15', '20']\n",
    "# As métricas que você quer na tabela (RMSE e MAE)\n",
    "METRICS_TO_CALCULATE = ['rmse', 'mae']\n",
    "# O nome do arquivo de saída\n",
    "OUTPUT_FILE = 'tabela_latex_resultados.txt'\n",
    "#-----------------------\n",
    "\n",
    "def process_imputation_results(base_path, rates, metrics):\n",
    "    \"\"\"\n",
    "    Lê todos os arquivos CSV, calcula as médias e desvios padrão,\n",
    "    e formata a tabela LaTeX.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    print(f\"Iniciando processamento em: {base_path}\")\n",
    "\n",
    "    # 1. Ler todos os arquivos CSV\n",
    "    for rate in rates:\n",
    "        dir_path = os.path.join(base_path, rate)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            print(f\"Aviso: Diretório não encontrado, pulando: {dir_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Pega todos os arquivos CSV no diretório\n",
    "        file_list = glob.glob(os.path.join(dir_path, '*.csv'))\n",
    "        \n",
    "        if not file_list:\n",
    "            print(f\"Aviso: Nenhum arquivo .csv encontrado em {dir_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Lendo {len(file_list)} arquivos de {dir_path}...\")\n",
    "        \n",
    "        for file_path in file_list:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                # Adiciona a taxa de missing data como uma coluna\n",
    "                df['missing_rate'] = int(rate)\n",
    "                all_data.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao ler {file_path}: {e}\")\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"Erro: Nenhum dado foi lido. Verifique o BASE_PATH.\")\n",
    "        return\n",
    "\n",
    "    # 2. Combinar tudo em um único DataFrame\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # 3. Calcular as estatísticas (média e desvio padrão)\n",
    "    # Agrupando por técnica e taxa de missing data\n",
    "    stats_df = combined_df.groupby(['imputation_technique', 'missing_rate'])[metrics].agg(['mean', 'std'])\n",
    "    \n",
    "    # Reorganizar o DataFrame para facilitar a formatação\n",
    "    # Isso transforma as 'missing_rate' em colunas\n",
    "    table_data = stats_df.unstack(level='missing_rate')\n",
    "\n",
    "    # 4. Gerar a string da tabela LaTeX\n",
    "    latex_string = generate_latex_table(table_data, rates, metrics)\n",
    "    \n",
    "    # 5. Salvar o resultado em um arquivo .txt\n",
    "    try:\n",
    "        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "            f.write(latex_string)\n",
    "        print(f\"\\nSucesso! Tabela salva em: {OUTPUT_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro ao salvar o arquivo: {e}\")\n",
    "\n",
    "def generate_latex_table(table_data, rates, metrics):\n",
    "    \"\"\"\n",
    "    Formata os dados estatísticos em uma string de tabela LaTeX.\n",
    "    \"\"\"\n",
    "    # Lista de técnicas (índice do dataframe)\n",
    "    techniques = table_data.index\n",
    "    \n",
    "    # Inicia a string da tabela\n",
    "    output_lines = []\n",
    "    \n",
    "    # --- Cabeçalho ---\n",
    "    # Linha 1 (Taxas de Missing Data)\n",
    "    header_line1 = r\"\\multirow{2}{*}{\\textbf{Imputation Technique}} & \"\n",
    "    cols = []\n",
    "    for rate in rates:\n",
    "        cols.append(fr\"\\multicolumn{{{len(metrics)}}}{{\\c}}{{\\textbf{{{rate}\\%}}}}\")\n",
    "    header_line1 += \" & \".join(cols) + r\" \\\\\"\n",
    "    output_lines.append(r\"\\hline \\hline\")\n",
    "    output_lines.append(header_line1)\n",
    "    \n",
    "    # Linha 2 (Métricas: RMSE e MAE)\n",
    "    header_line2 = \" & \"\n",
    "    metric_cols = []\n",
    "    for _ in rates:\n",
    "        for metric in metrics:\n",
    "            metric_cols.append(fr\"\\textbf{{{metric.upper()}}}\")\n",
    "    header_line2 += \" & \".join(metric_cols) + r\" \\\\\"\n",
    "    output_lines.append(r\"\\cline{2-\" + str(len(metric_cols) + 1) + \"}\")\n",
    "    output_lines.append(header_line2)\n",
    "    output_lines.append(r\"\\hline\")\n",
    "    \n",
    "    # --- Linhas de Dados ---\n",
    "    for tech in techniques:\n",
    "        line_parts = [f\"{tech.ljust(8)}\"] # Nome da técnica com espaçamento\n",
    "        \n",
    "        # Acessa os dados da técnica\n",
    "        tech_data = table_data.loc[tech]\n",
    "        \n",
    "        for rate in rates:\n",
    "            for metric in metrics:\n",
    "                try:\n",
    "                    # Tenta pegar média e desvio padrão\n",
    "                    mean_val = tech_data[(metric, 'mean', int(rate))]\n",
    "                    std_val = tech_data[(metric, 'std', int(rate))]\n",
    "                    \n",
    "                    # Formata como \"média ± desvio\"\n",
    "                    cell_text = fr\"{mean_val:.2f} $\\pm$ {std_val:.2f}\"\n",
    "                    line_parts.append(cell_text)\n",
    "                    \n",
    "                except KeyError:\n",
    "                    # Caso não exista dado para essa combinação\n",
    "                    print(f\"Aviso: Dados não encontrados para {tech}, {rate}%, {metric}\")\n",
    "                    line_parts.append(\" - \")\n",
    "        \n",
    "        # Junta tudo com o separador de coluna do LaTeX\n",
    "        output_lines.append(\" & \".join(line_parts) + r\" \\\\\")\n",
    "\n",
    "    output_lines.append(r\"\\hline\")\n",
    "    \n",
    "    print(\"\\n--- Pré-visualização da Tabela ---\")\n",
    "    print(\"\\n\".join(output_lines))\n",
    "    \n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "# --- Ponto de entrada do Script ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Verifica se o pandas está instalado\n",
    "    try:\n",
    "        import pandas\n",
    "    except ImportError:\n",
    "        print(\"Erro: A biblioteca 'pandas' não está instalada.\")\n",
    "        print(\"Por favor, instale com: pip install pandas\")\n",
    "        exit()\n",
    "        \n",
    "    process_imputation_results(BASE_PATH, MISSING_RATES, METRICS_TO_CALCULATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c0e2268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processamento em: ..\\results\\imputation\\imputed_sample_data\n",
      "Lendo 10 arquivos de ..\\results\\imputation\\imputed_sample_data\\5...\n",
      "Lendo 10 arquivos de ..\\results\\imputation\\imputed_sample_data\\10...\n",
      "Lendo 10 arquivos de ..\\results\\imputation\\imputed_sample_data\\15...\n",
      "Lendo 10 arquivos de ..\\results\\imputation\\imputed_sample_data\\20...\n",
      "\n",
      "Dados carregados e preparados com 1200 linhas.\n",
      "Criando diretório de saída: visualizacoes_resultados\n",
      "Gerando gráficos de linha (Solução 1)...\n",
      "Gráficos de linha salvos em: visualizacoes_resultados\\graficos_de_linha_por_dataset.png\n",
      "Gerando gráficos de barras (Solução 2)...\n",
      "  - Processando barras para: esmond data perfsonar-ankara.ulakbim.gov.tr to psmp-gn-bw-lis-pt.geant.org 10-24-2023\n",
      "Erro ao gerar gráfico de barras para esmond data perfsonar-ankara.ulakbim.gov.tr to psmp-gn-bw-lis-pt.geant.org 10-24-2023: seaborn.axisgrid.FacetGrid() got multiple values for keyword argument 'sharey'\n",
      "  - Processando barras para: esmond data perfsonar-ankara.ulakbim.gov.tr to psmp-gn-bw-poz-pl.geant.org 10-24-2023\n",
      "Erro ao gerar gráfico de barras para esmond data perfsonar-ankara.ulakbim.gov.tr to psmp-gn-bw-poz-pl.geant.org 10-24-2023: seaborn.axisgrid.FacetGrid() got multiple values for keyword argument 'sharey'\n",
      "  - Processando barras para: esmond data perfsonar-sonda.rediris.es to psmp-gn-bw-lis-pt.geant.org 10-24-2023\n",
      "Erro ao gerar gráfico de barras para esmond data perfsonar-sonda.rediris.es to psmp-gn-bw-lis-pt.geant.org 10-24-2023: seaborn.axisgrid.FacetGrid() got multiple values for keyword argument 'sharey'\n",
      "  - Processando barras para: esmond data psmall.lut.ac.uk to psmp-gn-bw-vie-at.geant.org 10-24-2023\n",
      "Erro ao gerar gráfico de barras para esmond data psmall.lut.ac.uk to psmp-gn-bw-vie-at.geant.org 10-24-2023: seaborn.axisgrid.FacetGrid() got multiple values for keyword argument 'sharey'\n",
      "  - Processando barras para: esmond data psmp-gn-bw-lis-pt.geant.org to perfsonar-ankara.ulakbim.gov.tr 10-24-2023\n",
      "Erro ao gerar gráfico de barras para esmond data psmp-gn-bw-lis-pt.geant.org to perfsonar-ankara.ulakbim.gov.tr 10-24-2023: seaborn.axisgrid.FacetGrid() got multiple values for keyword argument 'sharey'\n",
      "  - Processando barras para: esmond data psmp-gn-bw-lis-pt.geant.org to perfsonar.restena.lu 10-24-2023\n",
      "Erro ao gerar gráfico de barras para esmond data psmp-gn-bw-lis-pt.geant.org to perfsonar.restena.lu 10-24-2023: seaborn.axisgrid.FacetGrid() got multiple values for keyword argument 'sharey'\n",
      "  - Processando barras para: esmond data psmp-gn-bw-poz-pl.geant.org to perfsonar-ankara.ulakbim.gov.tr 10-24-2023\n",
      "Erro ao gerar gráfico de barras para esmond data psmp-gn-bw-poz-pl.geant.org to perfsonar-ankara.ulakbim.gov.tr 10-24-2023: seaborn.axisgrid.FacetGrid() got multiple values for keyword argument 'sharey'\n",
      "  - Processando barras para: esmond data psmp-gn-bw-poz-pl.geant.org to pspmp-anella.csuc.cat 10-24-2023\n",
      "Erro ao gerar gráfico de barras para esmond data psmp-gn-bw-poz-pl.geant.org to pspmp-anella.csuc.cat 10-24-2023: seaborn.axisgrid.FacetGrid() got multiple values for keyword argument 'sharey'\n",
      "  - Processando barras para: esmond data psmp-gn-bw-vie-at.geant.org to psmall.lut.ac.uk 10-24-2023\n",
      "Erro ao gerar gráfico de barras para esmond data psmp-gn-bw-vie-at.geant.org to psmall.lut.ac.uk 10-24-2023: seaborn.axisgrid.FacetGrid() got multiple values for keyword argument 'sharey'\n",
      "  - Processando barras para: esmond data pspmp-anella.csuc.cat to psmp-gn-bw-poz-pl.geant.org 10-24-2023\n",
      "Erro ao gerar gráfico de barras para esmond data pspmp-anella.csuc.cat to psmp-gn-bw-poz-pl.geant.org 10-24-2023: seaborn.axisgrid.FacetGrid() got multiple values for keyword argument 'sharey'\n",
      "Gráficos de barras salvos em: visualizacoes_resultados\n",
      "Gerando heatmaps (Solução 3 - Por Dataset)...\n",
      "  - Processando heatmap para: esmond data perfsonar-ankara.ulakbim.gov.tr to psmp-gn-bw-lis-pt.geant.org 10-24-2023 / fam\n",
      "  - Processando heatmap para: esmond data perfsonar-ankara.ulakbim.gov.tr to psmp-gn-bw-lis-pt.geant.org 10-24-2023 / dtw_magnitude\n",
      "  - Processando heatmap para: esmond data perfsonar-ankara.ulakbim.gov.tr to psmp-gn-bw-lis-pt.geant.org 10-24-2023 / dtw_shape\n",
      "  - Processando heatmap para: esmond data perfsonar-ankara.ulakbim.gov.tr to psmp-gn-bw-poz-pl.geant.org 10-24-2023 / fam\n",
      "  - Processando heatmap para: esmond data perfsonar-ankara.ulakbim.gov.tr to psmp-gn-bw-poz-pl.geant.org 10-24-2023 / dtw_magnitude\n",
      "  - Processando heatmap para: esmond data perfsonar-ankara.ulakbim.gov.tr to psmp-gn-bw-poz-pl.geant.org 10-24-2023 / dtw_shape\n",
      "  - Processando heatmap para: esmond data perfsonar-sonda.rediris.es to psmp-gn-bw-lis-pt.geant.org 10-24-2023 / fam\n",
      "  - Processando heatmap para: esmond data perfsonar-sonda.rediris.es to psmp-gn-bw-lis-pt.geant.org 10-24-2023 / dtw_magnitude\n",
      "  - Processando heatmap para: esmond data perfsonar-sonda.rediris.es to psmp-gn-bw-lis-pt.geant.org 10-24-2023 / dtw_shape\n",
      "  - Processando heatmap para: esmond data psmall.lut.ac.uk to psmp-gn-bw-vie-at.geant.org 10-24-2023 / fam\n",
      "  - Processando heatmap para: esmond data psmall.lut.ac.uk to psmp-gn-bw-vie-at.geant.org 10-24-2023 / dtw_magnitude\n",
      "  - Processando heatmap para: esmond data psmall.lut.ac.uk to psmp-gn-bw-vie-at.geant.org 10-24-2023 / dtw_shape\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-lis-pt.geant.org to perfsonar-ankara.ulakbim.gov.tr 10-24-2023 / fam\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-lis-pt.geant.org to perfsonar-ankara.ulakbim.gov.tr 10-24-2023 / dtw_magnitude\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-lis-pt.geant.org to perfsonar-ankara.ulakbim.gov.tr 10-24-2023 / dtw_shape\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-lis-pt.geant.org to perfsonar.restena.lu 10-24-2023 / fam\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-lis-pt.geant.org to perfsonar.restena.lu 10-24-2023 / dtw_magnitude\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-lis-pt.geant.org to perfsonar.restena.lu 10-24-2023 / dtw_shape\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-poz-pl.geant.org to perfsonar-ankara.ulakbim.gov.tr 10-24-2023 / fam\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-poz-pl.geant.org to perfsonar-ankara.ulakbim.gov.tr 10-24-2023 / dtw_magnitude\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-poz-pl.geant.org to perfsonar-ankara.ulakbim.gov.tr 10-24-2023 / dtw_shape\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-poz-pl.geant.org to pspmp-anella.csuc.cat 10-24-2023 / fam\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-poz-pl.geant.org to pspmp-anella.csuc.cat 10-24-2023 / dtw_magnitude\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-poz-pl.geant.org to pspmp-anella.csuc.cat 10-24-2023 / dtw_shape\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-vie-at.geant.org to psmall.lut.ac.uk 10-24-2023 / fam\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-vie-at.geant.org to psmall.lut.ac.uk 10-24-2023 / dtw_magnitude\n",
      "  - Processando heatmap para: esmond data psmp-gn-bw-vie-at.geant.org to psmall.lut.ac.uk 10-24-2023 / dtw_shape\n",
      "  - Processando heatmap para: esmond data pspmp-anella.csuc.cat to psmp-gn-bw-poz-pl.geant.org 10-24-2023 / fam\n",
      "  - Processando heatmap para: esmond data pspmp-anella.csuc.cat to psmp-gn-bw-poz-pl.geant.org 10-24-2023 / dtw_magnitude\n",
      "  - Processando heatmap para: esmond data pspmp-anella.csuc.cat to psmp-gn-bw-poz-pl.geant.org 10-24-2023 / dtw_shape\n",
      "Heatmaps por dataset salvos em: visualizacoes_resultados\n",
      "Gerando heatmaps (Solução 4 - Combinado)...\n",
      "  - Processando heatmap combinado para: fam\n",
      "  - Processando heatmap combinado para: dtw_magnitude\n",
      "  - Processando heatmap combinado para: dtw_shape\n",
      "Heatmaps combinados salvos em: visualizacoes_resultados\n",
      "\n",
      "Processamento de visualização concluído!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Configurações ---\n",
    "# O diretório base onde as pastas 5, 10, 15, 20 estão\n",
    "BASE_PATH = os.path.join('..', 'results', 'imputation', 'imputed_sample_data')\n",
    "# As pastas de taxas de missing data que você quer processar\n",
    "MISSING_RATES = ['5', '10', '15', '20']\n",
    "# As métricas que você quer nos gráficos\n",
    "METRICS_TO_PLOT = ['fam', 'dtw_magnitude', 'dtw_shape']\n",
    "# O diretório onde os gráficos serão salvos\n",
    "OUTPUT_DIR = 'visualizacoes_resultados'\n",
    "#-----------------------\n",
    "\n",
    "def load_and_prepare_data(base_path, rates, metrics):\n",
    "    \"\"\"\n",
    "    Lê todos os arquivos CSV de todos os datasets e taxas,\n",
    "    combina-os em um DataFrame e o \"derrete\" (melts) para\n",
    "    o formato longo, ideal para o Seaborn.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    print(f\"Iniciando processamento em: {base_path}\")\n",
    "\n",
    "    # 1. Ler todos os arquivos CSV\n",
    "    for rate in rates:\n",
    "        dir_path = os.path.join(base_path, rate)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            print(f\"Aviso: Diretório não encontrado, pulando: {dir_path}\")\n",
    "            continue\n",
    "            \n",
    "        file_list = glob.glob(os.path.join(dir_path, '*.csv'))\n",
    "        \n",
    "        if not file_list:\n",
    "            print(f\"Aviso: Nenhum arquivo .csv encontrado em {dir_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Lendo {len(file_list)} arquivos de {dir_path}...\")\n",
    "        \n",
    "        for file_path in file_list:\n",
    "            try:\n",
    "                # Extrai o nome do dataset do nome do arquivo\n",
    "                # Pega tudo antes do primeiro \"_\"\n",
    "                basename = os.path.basename(file_path)\n",
    "                dataset_name = basename.split('_')[0]\n",
    "                \n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Adiciona as colunas de taxa e dataset\n",
    "                df['missing_rate'] = int(rate)\n",
    "                df['dataset'] = dataset_name\n",
    "                \n",
    "                # Verifica se as métricas existem\n",
    "                if all(metric in df.columns for metric in metrics):\n",
    "                    all_data.append(df)\n",
    "                else:\n",
    "                    print(f\"Aviso: Pulando {file_path}, nem todas as métricas {metrics} foram encontradas.\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao ler {file_path}: {e}\")\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"Erro: Nenhum dado foi lido. Verifique o BASE_PATH.\")\n",
    "        return None\n",
    "\n",
    "    # 2. Combinar tudo em um único DataFrame\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # 3. \"Derreter\" (Melt) o DataFrame\n",
    "    # Isso transforma as colunas de métrica (fam, dtw_mag, dtw_shape)\n",
    "    # em linhas, facilitando a plotagem com 'hue' ou 'row'.\n",
    "    \n",
    "    id_vars = ['dataset', 'missing_rate', 'imputation_technique']\n",
    "    # Garante que apenas as colunas necessárias estão presentes\n",
    "    columns_to_melt = id_vars + metrics\n",
    "    \n",
    "    # Filtra o DataFrame para evitar colunas desnecessárias no melt\n",
    "    try:\n",
    "        meltable_df = combined_df[columns_to_melt]\n",
    "    except KeyError as e:\n",
    "        print(f\"Erro: Coluna faltando no DataFrame. Verifique se os CSVs contêm as colunas: {e}\")\n",
    "        print(\"Colunas encontradas:\", combined_df.columns)\n",
    "        return None\n",
    "        \n",
    "    long_df = meltable_df.melt(\n",
    "        id_vars=id_vars,\n",
    "        value_vars=metrics,\n",
    "        var_name='metric',\n",
    "        value_name='value'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDados carregados e preparados com {len(long_df)} linhas.\")\n",
    "    return long_df\n",
    "\n",
    "def plot_line_charts(df, output_dir):\n",
    "    \"\"\"\n",
    "    Solução 1: Gráficos de Linha (Recomendado)\n",
    "    Gera uma grade de gráficos de linha, separados por dataset e métrica.\n",
    "    \"\"\"\n",
    "    print(\"Gerando gráficos de linha (Solução 1)...\")\n",
    "    try:\n",
    "        g = sns.relplot(\n",
    "            data=df,\n",
    "            x=\"missing_rate\",\n",
    "            y=\"value\",\n",
    "            hue=\"imputation_technique\",\n",
    "            style=\"imputation_technique\", # Estilos de linha diferentes\n",
    "            markers=True,\n",
    "            col=\"dataset\",\n",
    "            row=\"metric\",\n",
    "            kind=\"line\",\n",
    "            legend=\"full\",\n",
    "            facet_kws={'sharey': False}, # Deixa o eixo Y livre\n",
    "            height=4,\n",
    "            aspect=1.2\n",
    "        )\n",
    "        \n",
    "        # Ajusta os títulos\n",
    "        g.set_titles(\"Dataset: {col_name} | Métrica: {row_name}\")\n",
    "        g.set_axis_labels(\"Taxa de Dados Faltantes (%)\", \"Valor da Métrica\")\n",
    "        \n",
    "        output_path = os.path.join(output_dir, \"graficos_de_linha_por_dataset.png\")\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Gráficos de linha salvos em: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar gráficos de linha: {e}\")\n",
    "\n",
    "def plot_bar_charts(df, output_dir):\n",
    "    \"\"\"\n",
    "    Solução 2: Gráficos de Barras Agrupados\n",
    "    Gera um arquivo de imagem separado PARA CADA DATASET.\n",
    "    \"\"\"\n",
    "    print(\"Gerando gráficos de barras (Solução 2)...\")\n",
    "    datasets = df['dataset'].unique()\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        print(f\"  - Processando barras para: {dataset}\")\n",
    "        try:\n",
    "            dataset_df = df[df['dataset'] == dataset]\n",
    "            \n",
    "            g = sns.catplot(\n",
    "                data=dataset_df,\n",
    "                x=\"imputation_technique\",\n",
    "                y=\"value\",\n",
    "                hue=\"missing_rate\",\n",
    "                row=\"metric\",\n",
    "                kind=\"bar\",\n",
    "                legend=\"full\",\n",
    "                facet_kws={'sharey': False},\n",
    "                height=4,\n",
    "                aspect=2.5\n",
    "            )\n",
    "            \n",
    "            g.set_titles(\"Dataset: \" + dataset + \" | Métrica: {row_name}\")\n",
    "            g.set_axis_labels(\"Técnica de Imputação\", \"Valor da Métrica\")\n",
    "            g.set_xticklabels(rotation=45, horizontalalignment='right')\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"grafico_barras_{dataset}.png\")\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao gerar gráfico de barras para {dataset}: {e}\")\n",
    "    \n",
    "    print(f\"Gráficos de barras salvos em: {output_dir}\")\n",
    "\n",
    "def plot_heatmaps(df, output_dir):\n",
    "    \"\"\"\n",
    "    Solução 3: Mapas de Calor (Heatmaps)\n",
    "    Gera um arquivo de imagem separado PARA CADA DATASET e CADA MÉTRICA.\n",
    "    \"\"\"\n",
    "    print(\"Gerando heatmaps (Solução 3 - Por Dataset)...\")\n",
    "    datasets = df['dataset'].unique()\n",
    "    metrics = df['metric'].unique()\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        for metric in metrics:\n",
    "            print(f\"  - Processando heatmap para: {dataset} / {metric}\")\n",
    "            try:\n",
    "                # Filtra os dados\n",
    "                subset = df[(df['dataset'] == dataset) & (df['metric'] == metric)]\n",
    "                \n",
    "                # Pivota os dados para o formato do heatmap\n",
    "                pivot_df = subset.pivot(\n",
    "                    index=\"imputation_technique\",\n",
    "                    columns=\"missing_rate\",\n",
    "                    values=\"value\"\n",
    "                )\n",
    "                \n",
    "                # Define o esquema de cores (invertido para FAM)\n",
    "                cmap = \"viridis_r\" if metric == 'fam' else \"viridis\"\n",
    "                \n",
    "                # Cria a figura\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(\n",
    "                    pivot_df,\n",
    "                    annot=True,     # Escreve o valor na célula\n",
    "                    fmt=\".2f\",      # Formato com 2 casas decimais\n",
    "                    linewidths=.5,\n",
    "                    cmap=cmap\n",
    "                )\n",
    "                \n",
    "                plt.title(f\"Heatmap - Métrica: {metric.upper()} | Dataset: {dataset}\")\n",
    "                plt.xlabel(\"Taxa de Dados Faltantes (%)\")\n",
    "                plt.ylabel(\"Técnica de Imputação\")\n",
    "                \n",
    "                output_path = os.path.join(output_dir, f\"heatmap_{dataset}_{metric}.png\")\n",
    "                plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao gerar heatmap para {dataset} / {metric}: {e}\")\n",
    "\n",
    "    print(f\"Heatmaps por dataset salvos em: {output_dir}\")\n",
    "\n",
    "def plot_combined_heatmaps(df, output_dir):\n",
    "    \"\"\"\n",
    "    Solução 4: Mapas de Calor Combinados\n",
    "    Gera um heatmap por métrica, combinando todos os datasets.\n",
    "    \"\"\"\n",
    "    print(\"Gerando heatmaps (Solução 4 - Combinado)...\")\n",
    "    metrics = df['metric'].unique()\n",
    "    \n",
    "    for metric in metrics:\n",
    "        print(f\"  - Processando heatmap combinado para: {metric}\")\n",
    "        try:\n",
    "            # Filtra os dados\n",
    "            subset = df[df['metric'] == metric].copy()\n",
    "            \n",
    "            # Cria uma nova coluna combinando dataset e técnica\n",
    "            subset['dataset_technique'] = subset['dataset'] + ' - ' + subset['imputation_technique']\n",
    "            \n",
    "            # Pivota os dados\n",
    "            pivot_df = subset.pivot(\n",
    "                index=\"dataset_technique\",\n",
    "                columns=\"missing_rate\",\n",
    "                values=\"value\"\n",
    "            )\n",
    "            \n",
    "            # Ordena o índice para agrupar datasets\n",
    "            pivot_df = pivot_df.sort_index()\n",
    "            \n",
    "            # Define o esquema de cores (invertido para FAM)\n",
    "            cmap = \"viridis_r\" if metric == 'fam' else \"viridis\"\n",
    "            \n",
    "            # Calcula a altura dinâmica do gráfico\n",
    "            num_rows = len(pivot_df.index)\n",
    "            fig_height = max(10, num_rows * 0.4) # 0.4 polegadas por linha\n",
    "            \n",
    "            # Cria a figura\n",
    "            plt.figure(figsize=(12, fig_height))\n",
    "            sns.heatmap(\n",
    "                pivot_df,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                linewidths=.5,\n",
    "                cmap=cmap\n",
    "            )\n",
    "            \n",
    "            plt.title(f\"Heatmap Combinado - Métrica: {metric.upper()}\")\n",
    "            plt.xlabel(\"Taxa de Dados Faltantes (%)\")\n",
    "            plt.ylabel(\"Dataset - Técnica de Imputação\")\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"heatmap_combinado_{metric}.png\")\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao gerar heatmap combinado para {metric}: {e}\")\n",
    "            \n",
    "    print(f\"Heatmaps combinados salvos em: {output_dir}\")\n",
    "\n",
    "def process_and_visualize_results(base_path, rates, metrics, output_dir):\n",
    "    \"\"\"\n",
    "    Função principal para orquestrar o carregamento e a geração\n",
    "    de todos os gráficos.\n",
    "    \"\"\"\n",
    "    # 1. Carregar e preparar os dados\n",
    "    long_df = load_and_prepare_data(base_path, rates, metrics)\n",
    "    \n",
    "    if long_df is None:\n",
    "        print(\"Processamento interrompido pois nenhum dado foi carregado.\")\n",
    "        return\n",
    "\n",
    "    # 2. Criar o diretório de saída se não existir\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Criando diretório de saída: {output_dir}\")\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # 3. Gerar os gráficos\n",
    "    plot_line_charts(long_df.copy(), output_dir)\n",
    "    plot_bar_charts(long_df.copy(), output_dir)\n",
    "    plot_heatmaps(long_df.copy(), output_dir)\n",
    "    plot_combined_heatmaps(long_df.copy(), output_dir) # <-- Nova função adicionada\n",
    "    \n",
    "    print(\"\\nProcessamento de visualização concluído!\")\n",
    "\n",
    "# --- Ponto de entrada do Script ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Verifica se as bibliotecas necessárias estão instaladas\n",
    "    try:\n",
    "        import pandas\n",
    "        import matplotlib\n",
    "        import seaborn\n",
    "    except ImportError as e:\n",
    "        print(f\"Erro: Biblioteca necessária não instalada: {e.name}\")\n",
    "        print(\"Por favor, instale as bibliotecas com:\")\n",
    "        print(\"pip install pandas matplotlib seaborn\")\n",
    "        exit()\n",
    "        \n",
    "    process_and_visualize_results(BASE_PATH, MISSING_RATES, METRICS_TO_PLOT, OUTPUT_DIR)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
